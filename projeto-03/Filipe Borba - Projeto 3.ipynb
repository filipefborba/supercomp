{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3: GPU\n",
    "### Filipe F. Borba  \n",
    "### Insper\n",
    "### Super Computação, Prof. Igor Montagner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O problema explorado nesse projeto é o algoritmo do Caixeiro Viajante. Este problema encontra-se na área de Otimização discreta, que estuda problemas de otimização baseados em uma sequência de escolhas e que a solução ótima só pode ser encontrada se enumerarmos todas as escolhas possíveis. Em outras palavras, só conseguimos achar a solução ótima se tivermos todas as soluções possíveis. Assim, não existem algoritmos mais eficientes de resolução, pois todos tem complexidade O(2^n) ou pior.\n",
    "\n",
    "Ao realizar esse teste das sequências de escolhas em paralelo, podemos diminuir consideravelmente o consumo de tempo do programa, o que é bastante interessante para computacão paralela. Contudo, conseguimos potencializar ainda mais essa solução ao utilizar uma GPU que supera a CPU nesses casos, pois possui centenas de threads disponíveis para realizar os cálculos.\n",
    "\n",
    "O problema do Caixeiro Viajante é o seguinte:\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/a4d91635c96d345fc31068a4420834d23654f82b/68747470733a2f2f75706c6f61642e77696b696d656469612e6f72672f77696b6970656469612f636f6d6d6f6e732f7468756d622f312f31312f474c504b5f736f6c7574696f6e5f6f665f615f74726176656c6c696e675f73616c65736d616e5f70726f626c656d2e7376672f35313270782d474c504b5f736f6c7574696f6e5f6f665f615f74726176656c6c696e675f73616c65736d616e5f70726f626c656d2e7376672e706e67\" alt=\"TSP\" style=\"width: 300px;\"/>\n",
    "\n",
    "```Um vendedor possui uma lista de empresas que ele deverá visitar em um certo dia. Não existe uma ordem fixa: desde que todos sejam visitados seu objetivo do dia está cumprido. Interessado em passar o maior tempo possível nos clientes ele precisa encontrar a sequência de visitas que resulta no menor caminho.```\n",
    "\n",
    "Para nosso projeto em específico, temos algumas simplificações:\n",
    "- o nosso caixeiro usa Waze e já sabe qual é o caminho com a menor distância entre dois pontos;\n",
    "- ele começa seu trajeto na empresa 0. Ou seja, basta ele encontrar um trajeto que passe por todas as outras e volte a empresa ```0```;\n",
    "- ele não pode passar duas vezes na mesma empresa. Ou seja, a saída é uma permutação de ```0 ... (N-1)```\n",
    "\n",
    "\n",
    "\n",
    "Finalmente, os objetivos deste projeto são\n",
    "\n",
    "1. implementar uma versão GPU em C++ do caixeiro viajante a partir de uma versão sequencial em C++.\n",
    "2. Estudar e implementar os seguintes métodos paralelos:\n",
    "    * busca local paralela usando 2-opt\n",
    "\n",
    "** Como descrito em https://github.com/Insper/supercomp/blob/master/projeto-02/enunciado.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organização do Projeto\n",
    "\n",
    "O projeto foi realizado utilizando a linguagem C++ e o compilador nvcc do CUDA na máquina p2.xlarge da AWS (que possui uma GPU NVIDIA Tesla K80). Temos, então, alguns arquivos diferentes.\n",
    "\n",
    "* Arquivo random_sol.cu, que gera 10.000 soluções aleatórias e retorna o melhor resultado entre elas.\n",
    "* Arquivo 2opt_sol.cu, que gera 10.000 soluções aleatórias, mas as otimiza utilizando a busca local 2-opt.\n",
    "\n",
    "Além disso, o projeto possui um CMakeLists.txt que possibilita a compilação dos executáveis. São eles:\n",
    "* random_sol (solução aleatória em GPU)\n",
    "* 2opt_spl (solução aleatória em GPU com otimização 2-opt)\n",
    "* time_random_sol (com print de tempo - solução aleatória em GPU)\n",
    "* time_2opt_spl (com print de tempo - solução aleatória em GPU com otimização 2-opt)\n",
    "\n",
    "OBS: os outros executáveis foram criados para que a saída devolvesse o tempo, mas o código neles é igual.\n",
    "\n",
    "Para compilar todos os executáveis, basta usar os seguintes comandos na pasta raíz do projeto:\n",
    "\n",
    "```mkdir build; cd build; cmake ..; make ```\n",
    "\n",
    "O comando ```make``` é responsável por compilar os executáveis.\n",
    "Após isso, para iniciar cada executável, basta utilizar o comando \n",
    "\n",
    "```./nome_do_arquivo < ../tests/nome_da_entrada```\n",
    "\n",
    "dentro da pasta ```build```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com CPU\n",
    "\n",
    "O projeto em GPU tem diferenças bastante significativas em relação ao projeto em CPU. Podemos comparar com uma lista de prós em contras.\n",
    "\n",
    "Projeto GPU:  \n",
    "  \n",
    "Vantagens:\n",
    "- Consegue lidar com entradas muito maiores (CPU travava com 15, GPU roda em alguns ms entrada de tamanho 32).\n",
    "- Problemas intratáveis em paralelo acabam sendo tratáveis, pois temos tempos mais razoáveis de execução.\n",
    "\n",
    "Desvantagens:\n",
    "- Maior dificuldade de paralelizar o código (código CUDA mais difícil que OpenMP).\n",
    "- Não devolve o caminho ótimo nesse caso.\n",
    "\n",
    "Podemos então concluir que a implementação em paralelo para problemas pequenos é bastante interessante, pois temos a solução ótima nesses casos. Contudo, para problemas maiores, a solução paralela demora muito mais, então a GPU acaba \"brilhando\" nesse caso. Apesar de não trazer a solução ótima, ela consegue computar o problema. \n",
    "\n",
    "Vejamos como isso se comporta na prática:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"/home/filipefborba/Documents/Keys/IgorNvidia.pem\"\n",
    "host = \"ec2-user@ec2-174-129-76-48.compute-1.amazonaws.com\" # MUDAR O IP AQUI\n",
    "working_directory = \"/home/ec2-user/borba/supercomp/projeto-03/\" # MUDAR A PASTA AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Realizar o build na máquina da aws.\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory, \"&&\", \"mkdir\", \"build\"]))\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"cmake ..\"]))\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"make\", \"-j4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2opt-sol', 'random-sol', 'tsp-bb']\n",
      "['time-2opt-sol', 'time-random-sol', 'time-tsp-bb']\n"
     ]
    }
   ],
   "source": [
    "# Listar os executaveis\n",
    "output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"ls\"])\n",
    "output = output.decode(\"utf-8\").splitlines()\n",
    "files = sorted([x for x in output if ((x.endswith(\"sol\") or x.endswith(\"bb\")) and not x.startswith(\"time\"))])\n",
    "files_time = sorted([x for x in output if ((x.endswith(\"sol\") or x.endswith(\"bb\")) and x.startswith(\"time\"))])\n",
    "print(files)\n",
    "print(files_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['berlin52.txt', 'ch130.txt', 'gil262.txt', 'pr439.txt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pegar o nome das entradas. VEJA QUE ISSO É LOCAL E NAO NA AWS!\n",
    "inputs = sorted([n for n in os.listdir(\"./tests/\") if n.endswith('.txt') and not n.startswith(\"in\")])\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste básico para mostrar a diferença na saida\n",
    "def run_basic_test(file, input_file):\n",
    "    with open('./tests/' + input_file, 'rb', 0) as f:\n",
    "        output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\",\n",
    "                                     f\"./{file}\"], stdin=f, stderr=subprocess.STDOUT)\n",
    "        output = output.decode(\"utf-8\").splitlines()\n",
    "    \n",
    "    print(f\"--{file}------{input_file}--\")\n",
    "    print(\"\\n\".join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ssh', '-i', '/home/filipefborba/Documents/Keys/IgorNvidia.pem', 'ec2-user@ec2-174-129-76-48.compute-1.amazonaws.com', 'cd', '/home/ec2-user/borba/supercomp/projeto-03/build/', '&&', './time-2opt-sol']' returned non-zero exit status 134.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-05e8ebc5eadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# O teste usado é o in10.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mrun_basic_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"in10.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-f536c82f38c2>\u001b[0m in \u001b[0;36mrun_basic_test\u001b[0;34m(file, input_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tests/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\",\n\u001b[0;32m----> 5\u001b[0;31m                                      f\"./{file}\"], stdin=f, stderr=subprocess.STDOUT)\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0;32m--> 356\u001b[0;31m                **kwargs).stdout\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             raise CalledProcessError(retcode, process.args,\n\u001b[0;32m--> 438\u001b[0;31m                                      output=stdout, stderr=stderr)\n\u001b[0m\u001b[1;32m    439\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mCompletedProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ssh', '-i', '/home/filipefborba/Documents/Keys/IgorNvidia.pem', 'ec2-user@ec2-174-129-76-48.compute-1.amazonaws.com', 'cd', '/home/ec2-user/borba/supercomp/projeto-03/build/', '&&', './time-2opt-sol']' returned non-zero exit status 134."
     ]
    }
   ],
   "source": [
    "# O teste usado é o in10.txt\n",
    "for f in files_time:\n",
    "    run_basic_test(f, \"in10.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Testes de Desempenho\n",
    "\n",
    "Aqui estamos preocupados com a diferença de desempenho, então o tamanho das entradas é maior. O tempo foi medido a partir da biblioteca <cuda_runtime.h> e o nvprof do próprio CUDA. Testaremos então o tempo de uma execução e a saída para as duas soluções em GPU (aleatório e 2-opt). Para isso, existem alguns testes do TSPLIB já resolvidos que serão utilizados como base aqui. São eles:\n",
    "- berlin52.txt (N = 52) // Pequeno\n",
    "- ch130.txt (N = 130)   // Médio\n",
    "- gil262.txt (N = 262)  // Grande\n",
    "- pr439.txt (N = 439)   // Muito Grande\n",
    "\n",
    "Esses testes foram escolhidos pois já representam uma grande diferença de desempenho entre os executáveis. O pr439 serve mais para verificar os limites da máquina em termos de memória e processamentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter us para ms\n",
    "def fix_time(time):\n",
    "    if (time.endswith(\"us\")):\n",
    "        return float(time[:-2])/1000\n",
    "    elif (time.endswith(\"ms\")):\n",
    "        return float(time[:-2])\n",
    "    elif (time.endswith(\"s\")):\n",
    "        return float(time[:-1])*1000\n",
    "    else:\n",
    "        print(\"time not us, ms or s\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar nome e tempo de execucao\n",
    "def get_name_and_time(output, name):\n",
    "    if (name == \"2opt_sol\"):\n",
    "        name = \"opt_sol\"\n",
    "    for s in output:\n",
    "        found_name = s.find(name)\n",
    "        if found_name != -1:\n",
    "            result = s[found_name:found_name+len(name)]\n",
    "            found_time = re.search('%(.*)s ', s)\n",
    "            if (found_time == None):\n",
    "                pass\n",
    "            else:\n",
    "                print(found_time.group(1).split()[0], result)\n",
    "                return found_time.group(1).split()[0], result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempos de alocacao e copia de memoria, alem de kernel.\n",
    "def run_nvprof_test(file, input_file):\n",
    "    with open('./tests/' + input_file, 'rb', 0) as f:\n",
    "        output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory, \"&&\",\n",
    "                                     \"nvprof\", f\"./{file}\"], stdin=f, stderr=subprocess.STDOUT)\n",
    "        output = output.decode(\"utf-8\").splitlines()\n",
    "    \n",
    "    print(f\"--{file}------{input_file}--\")\n",
    "    kernel_time, kernel_name = get_name_and_time(output, str(file))\n",
    "    htod_time, htod_name = get_name_and_time(output, \"[CUDA memcpy HtoD]\")\n",
    "    dtoh_time, dtoh_name = get_name_and_time(output, \"[CUDA memcpy DtoH]\")\n",
    "    malloc_time, malloc_name = get_name_and_time(output, \"cudaMalloc\")\n",
    "    kernel_time = fix_time(kernel_time)\n",
    "    htod_time = fix_time(htod_time)\n",
    "    dtoh_time = fix_time(dtoh_time)\n",
    "    malloc_time = fix_time(malloc_time)\n",
    "    return [file, input_file,\n",
    "        kernel_time, kernel_name,\n",
    "        htod_time, htod_name,\n",
    "        dtoh_time, dtoh_name,\n",
    "        malloc_time, malloc_name\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos rodar um teste básico para ver a qualidade da solucao. O ch130.txt é interessante.\n",
    "for f in files:\n",
    "    run_basic_test(f, \"ch130.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in inputs:\n",
    "    for f in files:\n",
    "        data.append(run_nvprof_test(f, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, dtype=np.float64, columns=[\"Executavel\", \"Entrada\", \"Tempo Kernel\", \"Nome Kernel\",\n",
    "                                                  \"Tempo HtoD\", \"Nome HtoD\", \"Tempo DtoH\", \"Nome DtoH\",\n",
    "                                                  \"Tempo Malloc\", \"Nome Malloc\"])\n",
    "df\n",
    "\n",
    "# Todos os tempos estão em milissegundos!\n",
    "# Coluna 0: Executável\n",
    "# Coluna 1: Entrada\n",
    "# Coluna 2: Tempo de execução Kernel\n",
    "# Coluna 3: Nome kernel\n",
    "# Coluna 4: Tempo de execução Memcpy\n",
    "# Coluna 5: Nome memcpy HtoD\n",
    "# Coluna 6: Tempo de execução Memcpy\n",
    "# Coluna 7: Nome memcpy DtoH\n",
    "# Coluna 8: Tempo de execução Malloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferença alocacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group[1], group[2], marker='o', linestyle='-', ms=5, label=group[0])\n",
    "plt.title('Tempos para executáveis diferentes')\n",
    "plt.ylabel('Tempo (ms)')\n",
    "plt.xlabel('Entrada Utilizada')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos verificar no gráfico acima, o algoritmo 2opt_sol acaba sendo MUITO mais lento que o random_sol. Isso acontece porque o 2opt realiza 2 fors que permutam a solução aleatória com o objetivo de encontrar um custo melhor. Além disso, para cada permutação, ele recalcula o custo total, sendo, novamente, bem ineficiente em termos de operações.  \n",
    "Contudo, como pudemos verificar nos testes básicos, o 2opt acaba encontrando caminhos com custo bem menores, o que acaba sendo muito interessante, visto que sua implementação está totalmente ingênua.\n",
    "\n",
    "Ainda, verificando o dataframe, podemos verificar que o tempo de alocação de memória e cópia acaba sendo quase insignificante perto do tempo de processamento do kernel das funções. Esse efeito acaba crescendo muito quanto maior as entradas: o tempo de \"preparação\" é mínimo e de processamento é máximo.\n",
    "\n",
    "Para melhorar o programa, seria necessário otimizar a memória e balancear melhor as cargas das threads. Ainda, seria interessante a utilização do Branch and Bound nesse caso, mas a implementação não é tão trivial. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
