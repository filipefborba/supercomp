{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrega GPU IV - Shared\n",
    "### Filipe F. Borba  \n",
    "### Insper\n",
    "### Super Computação, Prof. Igor Montagner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução\n",
    "\n",
    "O objetivo dessa entrega é comparar diversos algoritmos de multiplicação de matrizes para verificar a diferença das implementações em GPU. Com isso, foram utilizados vetores de tamanho size * size, onde size está em [128, 512, 1024]. Ao utilizar um vetor de tamanho 2048 o programa começava a demorar demais para as soluções mais fracas. A máquina utilizada foi uma p2.xlarge da AWS, que possui uma GPU NVIDIA Tesla K80."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"/home/filipefborba/Documents/Keys/IgorNvidia.pem\"\n",
    "host = \"ec2-user@ec2-54-80-199-115.compute-1.amazonaws.com\" # MUDAR O IP AQUI\n",
    "working_directory = \"/home/ec2-user/borba/supercomp/15-gpu-IV/\" # MUDAR A PASTA AQUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Realizar o build na máquina da aws.\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory, \"&&\", \"mkdir\", \"build\"]))\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"cmake ..\"]))\n",
    "print(subprocess.call([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"make\", \"-j4\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listar os executaveis\n",
    "output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\", \"ls\"])\n",
    "output = output.decode(\"utf-8\").splitlines()\n",
    "files = sorted([x for x in output if (x.startswith(\"naive\") or x.startswith(\"par\") or x.startswith(\"seq\") or x.startswith(\"tiling\"))])\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devolve o output e o tempo de execucao\n",
    "def run_test(file, vsize):\n",
    "    output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory, \"&&\",\n",
    "                                 f\"./{file}{vsize}\"])\n",
    "    output = output.decode(\"utf-8\").splitlines()\n",
    "     \n",
    "    print(f\"--{file}------{vsize}--\")\n",
    "    print(output[0])\n",
    "    return [file, vsize, float(output[0][6:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempo de Execução\n",
    "data = []\n",
    "for v in vector_sizes[:-1]:\n",
    "    for f in files:\n",
    "        data.append(run_test(f[:-3], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter us para ms\n",
    "def fix_time(time):\n",
    "    if (time.endswith(\"us\")):\n",
    "        return float(time[:-2])/1000\n",
    "    elif (time.endswith(\"ms\")):\n",
    "        return float(time[:-2])\n",
    "    elif (time.endswith(\"s\")):\n",
    "        return float(time[:-1])*1000\n",
    "    else:\n",
    "        print(\"time not us, ms or s\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar nome e tempo de execucao\n",
    "def get_name_and_time(output, name):\n",
    "    if (name == \"tiling\"):\n",
    "        name = \"multMat\"\n",
    "    if (name == \"naive\"):\n",
    "        name = \"MatrixMulKernel\"\n",
    "    for s in output:\n",
    "        found_name = s.find(name)\n",
    "        if found_name != -1:\n",
    "            result = s[found_name:found_name+len(name)]\n",
    "            found_time = re.search('%(.*)s ', s)\n",
    "            if (found_time == None):\n",
    "                pass\n",
    "            else:\n",
    "                print(found_time.group(1).split()[0], result)\n",
    "                return found_time.group(1).split()[0], result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tempos de alocacao e copia de memoria, alem de kernel.\n",
    "def run_nvprof_test(file, input_file):\n",
    "    output = subprocess.check_output([\"ssh\", \"-i\", key, host, \"cd\", working_directory+\"build/\", \"&&\",\n",
    "                                 \"nvprof\", f\"./{file}\"], stderr=subprocess.STDOUT)\n",
    "    output = output.decode(\"utf-8\").splitlines()\n",
    "    \n",
    "    print(f\"--{file}------{input_file}--\")\n",
    "    kernel_time, kernel_name = get_name_and_time(output, str(file))\n",
    "    htod_time, htod_name = get_name_and_time(output, \"[CUDA memcpy HtoD]\")\n",
    "    dtoh_time, dtoh_name = get_name_and_time(output, \"[CUDA memcpy DtoH]\")\n",
    "    malloc_time, malloc_name = get_name_and_time(output, \"cudaMalloc\")\n",
    "    kernel_time = fix_time(kernel_time)\n",
    "    htod_time = fix_time(htod_time)\n",
    "    dtoh_time = fix_time(dtoh_time)\n",
    "    malloc_time = fix_time(malloc_time)\n",
    "    return [file, input_file,\n",
    "        kernel_time, kernel_name,\n",
    "        htod_time, htod_name,\n",
    "        dtoh_time, dtoh_name,\n",
    "        malloc_time, malloc_name\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gpu = []\n",
    "gpu_files = [\"naive.cu\", \"tiling.cu\"]\n",
    "for v in vector_sizes[1:]:\n",
    "    for f in gpu_files:\n",
    "        data_gpu.append(run_nvprof_test(f[:-3], v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados\n",
    "\n",
    "Aqui estamos preocupados com a diferença de desempenho, então foram plotados gráficos para verificar a diferença entre as soluções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, dtype=np.float64)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data_gpu, dtype=np.float64)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group[1], group[2], marker='o', linestyle='-', ms=5, label=group[0])\n",
    "plt.title('Tempos para executáveis diferentes')\n",
    "plt.ylabel('Tempo (ms)')\n",
    "plt.xlabel('Tamanho de Entrada')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df2.groupby(0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for name, group in groups:\n",
    "    ax.plot(group[1], group[2], marker='o', linestyle='-', ms=5, label=group[0])\n",
    "    \n",
    "plt.title('Tempos para executáveis diferentes')\n",
    "plt.ylabel('Tempo (ms)')\n",
    "plt.xlabel('Tamanho de Entrada')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, item in groups:\n",
    "    print(groups.get_group(key), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos verificar nos gráficos acima, o tempo de execução dos algoritmos que utilizam a GPU são muito menores, sendo o algoritmo de Tiling o mais eficiente. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
